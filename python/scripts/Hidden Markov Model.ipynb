{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_path = '/home/ajhnam/projects/hidden_singles_public/'\n",
    "pickle_path = '/data2/pdp/ajhnam/hidden_singles_public/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(proj_path + 'python/')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Dirichlet, Bernoulli, Categorical, Uniform\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "\n",
    "from hiddensingles.misc import torch_utils as tu\n",
    "from hiddensingles.misc import utils, TensorDict, TensorDictDataset, nnModule, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_responses(puzzle_data_path, subject_data_path, solvers=True, device='cpu'):\n",
    "    \"\"\"\n",
    "    Returns a tensor of shape [num_solvers, num_trials]\n",
    "    containing the response types of each subject for each trial\n",
    "    \"\"\"\n",
    "    puzzle_df = pd.read_csv(proj_path + puzzle_data_path, sep='\\t')\n",
    "    subject_df = pd.read_csv(proj_path + subject_data_path, sep='\\t')\n",
    "    subject_df = subject_df[~subject_df.solver.isna()]\n",
    "    subject_df.solver = subject_df.solver.astype(bool)\n",
    "    subject_df = subject_df[subject_df.solver if solvers else ~subject_df.solver]\n",
    "    subject_ids = set(subject_df.subject_id)\n",
    "\n",
    "    response_map = {'inhouse': 0,\n",
    "                    'absent': 1,\n",
    "                    'distractor': 2,\n",
    "                    'target': 3}\n",
    "    puzzle_df = puzzle_df[(puzzle_df.phase == 1) & (puzzle_df.subject_id.isin(subject_ids))]\n",
    "    num_trials = len(puzzle_df.trial.unique())\n",
    "    puzzle_df.response_type = [response_map[response] for response in puzzle_df.response_type]\n",
    "    puzzle_df = puzzle_df.sort_values(['subject_id', 'trial'])\n",
    "    responses = torch.tensor(puzzle_df.response_type.to_numpy(), device=device).view(-1, num_trials)\n",
    "    subject_ids = puzzle_df.subject_id.unique()\n",
    "    return responses, subject_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_strat_responses(p_lapse_ih, p_lapse_a, p_lapse_d):\n",
    "    \"\"\"\n",
    "    Returns P(response | strategy), i.e. probabilities of each response type given strategy\n",
    "    \"\"\"\n",
    "    device = p_lapse_ih.device\n",
    "    p = torch.tensor([[3/9, 4/9, 1/9, 1/9],\n",
    "                      [1,   4/6, 1/6, 1/6],\n",
    "                      [1,   1,   1/2, 1/2],\n",
    "                      [1,   1,   1,   1  ]], device=device)\n",
    "    \n",
    "    # for gradient to flow, need to assign values like this\n",
    "    multipliers = [[1,          1,              1,                          1],\n",
    "                   [p_lapse_ih, 1 - p_lapse_ih, 1 - p_lapse_ih,             1 - p_lapse_ih],\n",
    "                   [p_lapse_ih, p_lapse_a,      1 - p_lapse_ih - p_lapse_a, 1 - p_lapse_ih - p_lapse_a],\n",
    "                   [p_lapse_ih, p_lapse_a,      p_lapse_d,                  1 - p_lapse_ih - p_lapse_a - p_lapse_d]]\n",
    "    multipliers = tu.make_tensor(multipliers, dtype=torch.float32, device=device)\n",
    "    p = p * multipliers\n",
    "    return p\n",
    "    \n",
    "\n",
    "def zero_p_transitions(p_transitions):\n",
    "    assert p_transitions.shape == (4, 4)\n",
    "    M = torch.zeros_like(p_transitions)\n",
    "    for i in range(0, 4):\n",
    "        M[i, i:] = p_transitions[i, i:].softmax(-1)\n",
    "    return M\n",
    "\n",
    "def get_p_strategies(subject_responses,\n",
    "                     p_strat_trial0,\n",
    "                     p_transitions):\n",
    "    \"\"\"\n",
    "    Returns P(strategy | trial)\n",
    "    First, gets P(strategy | trial=1) by solving for\n",
    "        P(response | strategy) * P(strategy) = P(data)\n",
    "        at trial = 1.\n",
    "    Then uses transition matrix to get subsequent state distributions under Markov assumption.\n",
    "    \"\"\"\n",
    "    num_subjects, num_trials = subject_responses.shape\n",
    "    p_s = p_strat_trial0\n",
    "    p_strategies = [p_s]\n",
    "    \n",
    "    # use transition matrix to derive P(strategy | trial)\n",
    "    for i in range(num_trials-1):\n",
    "        p_s = p_transitions.T.matmul(p_s)\n",
    "        p_strategies.append(p_s)\n",
    "    p_strategies = torch.stack(p_strategies, dim=0)\n",
    "    return p_strategies\n",
    "\n",
    "def get_p_responses(p_strat_responses, p_strategies):\n",
    "    \"\"\"\n",
    "    Returns P(response | trial) by computing\n",
    "        sum{strategy} P(response | strategy, trial) * P(strategy | trial)\n",
    "    \"\"\"\n",
    "    return p_strategies.matmul(p_strat_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MacroModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 subject_responses,\n",
    "                 p_lapse_ih=0.1,\n",
    "                 p_lapse_a=0.1,\n",
    "                 p_lapse_d=0.1):\n",
    "        # cap p_lapse at 20%, though it wouldn't actually reach it, just to keep things somewhat reasonable\n",
    "        assert 0 < p_lapse_ih <= .2\n",
    "        assert 0 < p_lapse_a <= .2\n",
    "        assert 0 < p_lapse_d <= .2\n",
    "        \n",
    "        super().__init__()\n",
    "        self.subject_responses = subject_responses\n",
    "        \n",
    "        self.p_lapse_ih = nn.Parameter(tu.logit(torch.tensor(5 * p_lapse_ih))) # max it at 20%\n",
    "        self.p_lapse_a = nn.Parameter(tu.logit(torch.tensor(5 * p_lapse_a))) # max it at 20%\n",
    "        self.p_lapse_d = nn.Parameter(tu.logit(torch.tensor(5 * p_lapse_d))) # max it at 20%\n",
    "        self.p_strat_trial0 = nn.Parameter(torch.rand(4))\n",
    "        self.p_transitions = nn.Parameter(torch.rand(4, 4))\n",
    "        \n",
    "    def get_params(self, detach=True):\n",
    "        p_lapse_ih = self.p_lapse_ih.sigmoid() / 5\n",
    "        p_lapse_a = self.p_lapse_a.sigmoid() / 5\n",
    "        p_lapse_d = self.p_lapse_d.sigmoid() / 5\n",
    "        p_strat_responses = get_p_strat_responses(p_lapse_ih, p_lapse_a, p_lapse_d)\n",
    "        \n",
    "        params = TensorDict(p_lapse_ih = p_lapse_ih,\n",
    "                            p_lapse_a = p_lapse_a,\n",
    "                            p_lapse_d = p_lapse_d,\n",
    "                            p_strat_trial0 = self.p_strat_trial0.softmax(-1),\n",
    "                            p_transitions = zero_p_transitions(self.p_transitions),\n",
    "                            p_strat_responses = p_strat_responses)\n",
    "        if detach:\n",
    "            params = params.detach()\n",
    "        return params\n",
    "        \n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        In the forward calculation, only the first trial is used (to establish prior)\n",
    "        \"\"\"\n",
    "        num_subjects, num_trials = self.subject_responses.shape\n",
    "        params = self.get_params(detach=False)\n",
    "\n",
    "        p_strategies = get_p_strategies(self.subject_responses,\n",
    "                                        params.p_strat_trial0,\n",
    "                                        params.p_transitions)\n",
    "        p_responses = get_p_responses(params.p_strat_responses, p_strategies)\n",
    "        p_responses_exp = tu.expand_along_dim(p_responses, 0, num_subjects)\n",
    "        nll = tu.nll_loss(p_responses_exp.log(), self.subject_responses)\n",
    "        \n",
    "        return TensorDict(p_strategies=p_strategies,\n",
    "                          p_responses=p_responses,\n",
    "                          nll=nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_macro_model(subject_responses,\n",
    "                      num_epochs=1000,\n",
    "                      lr=.01,\n",
    "                      show_pbar=False,\n",
    "                      print_epochs=0):\n",
    "    \n",
    "    model = MacroModel(subject_responses)\n",
    "    model = model.to(subject_responses.device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    iterable = range(num_epochs + 1)\n",
    "    \n",
    "    if show_pbar > 0:\n",
    "        iterable = tqdm(iterable)\n",
    "        \n",
    "    for epoch in iterable:\n",
    "        optimizer.zero_grad()\n",
    "        results = model()\n",
    "        loss = results.nll\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if print_epochs > 0 and (epoch%print_epochs == 0 or epoch == num_epochs):\n",
    "            print(\"Epoch: {}, NLL: {}\".format(epoch, loss))\n",
    "            print(results.p_strategies[0])\n",
    "            model.get_params().print(round_digits=4)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micromodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_micro_models(responses,\n",
    "                     p_strat_priors,\n",
    "                     p_strat_responses,\n",
    "                     p_transitions,\n",
    "                     show_pbar=False):\n",
    "    \"\"\"\n",
    "    Returns a TensorDict with\n",
    "        paths: tensor of shape [num_paths, num_trials] indicating the strategy at each step\n",
    "        p_paths: tensor of shape [num_subjects, num_paths] with probability of each path\n",
    "    \"\"\"\n",
    "    device = responses.device\n",
    "\n",
    "    # tensor of P(actual response | strategy) for each strategy\n",
    "    # shape [num_subjects, num_trials, num_strategies]  i.e. [88, 25, 4]\n",
    "    likelihoods = tu.prepend_shape(p_strat_responses, responses.shape)\n",
    "    likelihoods = tu.swap_dims(likelihoods, -1, -2)\n",
    "    likelihoods = tu.select_subtensors(likelihoods, responses)\n",
    "\n",
    "    # These computations are faster on numpy than pytorch by 3-5x\n",
    "    p_strat_responses = p_strat_responses.cpu()\n",
    "    responses = responses.cpu().numpy()\n",
    "    p_strat_priors = p_strat_priors.cpu().numpy()\n",
    "    likelihoods = likelihoods.cpu().numpy()\n",
    "    p_transitions = p_transitions.cpu().numpy()\n",
    "    \n",
    "    all_p_paths = []\n",
    "    # for each subject, build P(path) using Bayes Theorem\n",
    "    num_samples, num_trials = responses.shape\n",
    "    iterable = range(num_samples)\n",
    "    if show_pbar:\n",
    "        iterable = tqdm(iterable)\n",
    "    for sid in iterable:\n",
    "        p_s = likelihoods[sid, 0] * p_strat_priors\n",
    "        p_s = p_s / np.expand_dims(p_s.sum(-1), axis=-1)\n",
    "        p_paths = p_s\n",
    "        paths = [(0,), (1,), (2,), (3,)]\n",
    "\n",
    "        for trial in range(1, num_trials):\n",
    "            new_paths = []\n",
    "            new_p_paths = []\n",
    "\n",
    "            for i, strat in itertools.product(range(len(paths)), range(4)):\n",
    "                path = paths[i]\n",
    "\n",
    "                # reject paths that switch to a worse strategy\n",
    "                # they need to be left out of the loop so that they aren't included in the normalizing sum (denominator)\n",
    "                if path[-1] > strat:\n",
    "                    continue\n",
    "\n",
    "                # P(path_{t-1}) x P(s | s_{t-1}) x P(r | s)\n",
    "                p_path = p_paths[i] * p_transitions[path[-1], strat] * likelihoods[sid, trial, strat]\n",
    "                new_p_paths.append(p_path)\n",
    "\n",
    "                new_paths.append(path + (strat,))\n",
    "\n",
    "            paths = new_paths\n",
    "            p_paths = np.stack(new_p_paths, axis=0)\n",
    "            p_paths = p_paths / p_paths.sum()\n",
    "\n",
    "        all_p_paths.append(p_paths)\n",
    "\n",
    "    all_p_paths = np.stack(all_p_paths, axis=0)\n",
    "    all_p_paths = torch.tensor(all_p_paths)\n",
    "    paths = torch.tensor(paths)\n",
    "\n",
    "    oh_paths = tu.one_hot_encode(paths)\n",
    "    p_strategies = tu.extend_mul(all_p_paths, oh_paths).sum(1)\n",
    "    p_responses = tu.extend_mul(p_strategies, p_strat_responses).sum(2)\n",
    "    return TensorDict(paths=paths,\n",
    "                      probs=all_p_paths,\n",
    "                      p_strategies=p_strategies,\n",
    "                      p_responses=p_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "solvers = True\n",
    "\n",
    "# Path of data files\n",
    "puzzle_path = \"data/processed/puzzle_data.tsv\"\n",
    "subject_path = \"data/processed/subject_data.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "subject_responses, subject_ids = load_responses(puzzle_path,\n",
    "                                                subject_path,\n",
    "                                                solvers=solvers,\n",
    "                                                device=device)\n",
    "\n",
    "# Create save directory\n",
    "group = 'solvers' if solvers else 'nonsolvers'\n",
    "dirpath = proj_path + 'data/hmm/{}/'.format(group)\n",
    "utils.mkdir(dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = False\n",
    "\n",
    "if load:\n",
    "    macro_model = MacroModel(subject_responses)\n",
    "    macro_model.load_state_dict(torch.load(pickle_path + 'macro_models_{}.mdl'.format(group)))\n",
    "    macro_model = macro_model.to(device)\n",
    "    macro_model.eval()\n",
    "    params = macro_model.get_params()\n",
    "    micro_models = TensorDict.load(pickle_path + 'micro_models_{}.td'.format(group)).to(device)\n",
    "else:\n",
    "    macro_model = train_macro_model(subject_responses, num_epochs=2000, show_pbar=True)\n",
    "    params = macro_model.get_params()\n",
    "    micro_models = fit_micro_models(subject_responses,\n",
    "                                    params.p_strat_trial0,\n",
    "                                    params.p_strat_responses,\n",
    "                                    params.p_transitions,\n",
    "                                    show_pbar=True)\n",
    "\n",
    "    # Save models\n",
    "    torch.save(macro_model.state_dict(), pickle_path + 'macro_models_{}.mdl'.format(group))\n",
    "    micro_models.save(pickle_path + 'micro_models_{}.td'.format(group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro model posterior distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = macro_model()\n",
    "df_strategy = TensorDict(probability=outputs.p_strategies).to_dataframe({0: 'trial', 1: 'strategy'})\n",
    "df_response = TensorDict(probability=outputs.p_responses).to_dataframe({0: 'trial', 1: 'response_type'})\n",
    "df_strategy.to_csv(dirpath + 'macro_p_strategy.tsv', sep='\\t', index=False)\n",
    "df_response.to_csv(dirpath + 'macro_p_response.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro model posterior distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(response) and P(strategy) for each participant\n",
    "\n",
    "p_responses = utils.to_dataframe(micro_model.p_responses, ['subject_id', 'trial', 'response_type'], 'probability')\n",
    "p_responses.subject_id = [subject_ids[s] for s in p_responses.subject_id]\n",
    "p_responses.to_csv(dirpath + \"subject_p_responses.tsv\".format(group), sep='\\t', index=False)\n",
    "\n",
    "p_strategies = utils.to_dataframe(micro_model.p_strategies, ['subject_id', 'trial', 'strategy'], 'probability')\n",
    "p_strategies.subject_id = [subject_ids[s] for s in p_strategies.subject_id]\n",
    "p_strategies.to_csv(dirpath + \"subject_p_strategies.tsv\".format(group), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top posterior strategy paths for each participant\n",
    "\n",
    "p_paths, path_idx = micro_model.probs.sort(-1, descending=True)\n",
    "p_paths = p_paths[:,:5]\n",
    "path_idx = path_idx[:,:5]\n",
    "\n",
    "p_paths = utils.to_dataframe(p_paths, ['subject_id', 'rank'], 'probability')\n",
    "p_paths.subject_id = [subject_ids[s] for s in p_paths.subject_id]\n",
    "p_paths.to_csv(dirpath + \"top_paths_probs.tsv\", sep='\\t', index=False)\n",
    "\n",
    "top_paths = []\n",
    "for i in range(len(subject_responses)):\n",
    "    idx = path_idx[i]\n",
    "    top_paths.append(micro_model.paths[idx])\n",
    "top_paths = torch.stack(top_paths, dim=0)\n",
    "top_paths = utils.to_dataframe(top_paths, ['subject_id', 'rank', 'trial'], 'strategy')\n",
    "top_paths.subject_id = [subject_ids[s] for s in top_paths.subject_id]\n",
    "top_paths.to_csv(dirpath + \"top_paths.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradual vs Discrete Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_strat0(p_strat_trial0, num_samples, include_hs=False):\n",
    "    if not include_hs:\n",
    "        p_strat_trial0 = tu.normalize(p_strat_trial0[:3])\n",
    "    strats = Categorical(p_strat_trial0).sample((num_samples, ))\n",
    "    return tu.one_hot_encode(strats, 4).float()\n",
    "\n",
    "def get_expected_num_strategy_observations(mean_p_strat_trial0,\n",
    "                                           mean_p_transitions,\n",
    "                                           num_subjects,\n",
    "                                           num_trials):\n",
    "    obs = [mean_p_strat_trial0.unsqueeze(0)]\n",
    "    for i in range(num_trials):\n",
    "        obs.append(obs[-1].mm(mean_p_transitions))\n",
    "    obs = torch.cat(obs, 0)\n",
    "    obs = (num_subjects * obs).sum(0)\n",
    "    return obs\n",
    "\n",
    "def get_p_strat_responses_dirichlet_params(mean_p_strat_trial0,\n",
    "                                           mean_p_transitions,\n",
    "                                           mean_p_strat_responses,\n",
    "                                           num_subjects,\n",
    "                                           num_trials):\n",
    "    obs = get_expected_num_strategy_observations(mean_p_strat_trial0,\n",
    "                                                 mean_p_transitions,\n",
    "                                                 num_subjects,\n",
    "                                                 num_trials)\n",
    "    return obs.unsqueeze(-1) * mean_p_strat_responses\n",
    "\n",
    "def get_p_transitions_dirichlet_params(mean_p_strat_trial0, mean_p_transitions, num_subjects, num_trials):\n",
    "    obs = get_expected_num_strategy_observations(mean_p_strat_trial0,\n",
    "                                                 mean_p_transitions,\n",
    "                                                 num_subjects,\n",
    "                                                 num_trials)\n",
    "    return obs.unsqueeze(-1) * mean_p_transitions \n",
    "\n",
    "def sample_p_strat_responses(mean_p_strat_trial0,\n",
    "                             mean_p_transitions,\n",
    "                             mean_p_strat_responses,\n",
    "                             num_subjects,\n",
    "                             num_trials,\n",
    "                             num_samples):\n",
    "    params = get_p_strat_responses_dirichlet_params(mean_p_strat_trial0,\n",
    "                                                    mean_p_transitions,\n",
    "                                                    mean_p_strat_responses,\n",
    "                                                    num_subjects,\n",
    "                                                    num_trials)\n",
    "    samples = Dirichlet(params).sample((num_samples, ))\n",
    "    samples = tu.round(samples, 8, keep_device=True) # to 0 out near-0 probabilities\n",
    "    return tu.normalize(samples)\n",
    "\n",
    "def sample_p_transitions(mean_p_strat_trial0, mean_p_transitions, num_subjects, num_trials, num_samples):\n",
    "    params = get_p_transitions_dirichlet_params(mean_p_strat_trial0, mean_p_transitions, num_subjects, num_trials)\n",
    "    samples = Dirichlet(params).sample((num_samples, ))\n",
    "    samples = tu.round(samples, 8, keep_device=True) # to 0 out near-0 probabilities\n",
    "    return tu.normalize(samples)\n",
    "\n",
    "def sample_p_strategies(p_strat0, p_transitions, discrete, num_trials):\n",
    "    \"\"\"\n",
    "    p_strat0: tensor of shape [num_samples, 4]\n",
    "    p_transitions: tensor of shape [num_samples, 4, 4]\n",
    "    discrete: if True, argmax's the strategy at each trial\n",
    "    \"\"\"\n",
    "    strategies = [p_strat0]\n",
    "    for i in range(num_trials - 1):\n",
    "        strat = strategies[-1].unsqueeze(1).bmm(p_transitions).squeeze(1)\n",
    "        if discrete:\n",
    "            strat = tu.one_hot_encode(Categorical(strat).sample(), 4).float()\n",
    "        strategies.append(strat)\n",
    "    strategies = torch.stack(strategies, 1)\n",
    "    return strategies\n",
    "\n",
    "def get_p_responses(p_strategies, p_strat_responses):\n",
    "    p_strategies = p_strategies.unsqueeze(-2)\n",
    "    p_strat_responses = tu.expand_along_dim(p_strat_responses, 1, p_strategies.shape[1]).contiguous()\n",
    "    p_responses = tu.bmm(p_strategies, p_strat_responses).squeeze(-2)\n",
    "    return p_responses\n",
    "\n",
    "def sample_responses(p_strategies, p_strat_responses):\n",
    "    p_responses = get_p_responses(p_strategies, p_strat_responses)\n",
    "    return Categorical(p_responses).sample()\n",
    "\n",
    "def get_p_response_sequence(p_strategies, p_strat_responses, subject_responses):\n",
    "    num_subjects = subject_responses.shape[0]\n",
    "    num_samples = p_strategies.shape[0]\n",
    "    p_responses = get_p_responses(p_strategies, p_strat_responses)\n",
    "    p_responses = tu.expand_along_dim(p_responses, 1, num_subjects)\n",
    "    subject_responses = tu.prepend_shape(subject_responses, num_samples)\n",
    "    log_prob = Categorical(p_responses).log_prob(subject_responses)\n",
    "    prob = log_prob.sum(-1).exp().mean(0)\n",
    "    return prob\n",
    "\n",
    "def get_bayes_factor(p_response_seq1, p_response_seq2):\n",
    "    p1 = .5\n",
    "\n",
    "    for i in np.random.permutation(len(p_response_seq1)):\n",
    "        num = p_response_seq1[i] * p1\n",
    "        den = num + (p_response_seq2[i] * (1 - p1))\n",
    "        p1 = num / den\n",
    "    \n",
    "    return p1 / (1 - p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Dirichlet distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate responses\n",
    "num_samples = 100\n",
    "num_trials = 25\n",
    "num_subjects = 88\n",
    "p_strat0 = sample_strat0(params.p_strat_trial0, num_samples, include_hs=True)\n",
    "p_transitions = sample_p_transitions(mean_p_strat_trial0=params.p_strat_trial0,\n",
    "                                     mean_p_transitions=params.p_transitions,\n",
    "                                     num_subjects=num_subjects,\n",
    "                                     num_trials=num_trials,\n",
    "                                     num_samples=num_samples)\n",
    "p_strat_responses = sample_p_strat_responses(mean_p_strat_trial0=params.p_strat_trial0,\n",
    "                                             mean_p_transitions=params.p_transitions,\n",
    "                                             mean_p_strat_responses=params.p_strat_responses,\n",
    "                                             num_subjects=num_subjects,\n",
    "                                             num_trials=num_trials,\n",
    "                                             num_samples=num_samples)\n",
    "p_disc_strategies = sample_p_strategies(p_strat0, p_transitions, True, num_trials)\n",
    "p_grad_strategies = sample_p_strategies(p_strat0, p_transitions, False, num_trials)\n",
    "\n",
    "# 100000 doesn't fit on GPU\n",
    "p_disc_strategies = p_disc_strategies.to('cpu')\n",
    "p_grad_strategies = p_grad_strategies.to('cpu')\n",
    "p_strat_responses = p_strat_responses.to('cpu')\n",
    "s_responses = subject_responses.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_p_response_seq = get_p_response_sequence(p_disc_strategies, p_strat_responses, s_responses)\n",
    "grad_p_response_seq = get_p_response_sequence(p_grad_strategies, p_strat_responses, s_responses)\n",
    "bayes_factor = get_bayes_factor(disc_p_response_seq, grad_p_response_seq)\n",
    "utils.kv_print(Bayes_factor=bayes_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Dirichlet Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate responses\n",
    "num_samples = 100\n",
    "num_trials = 25\n",
    "num_subjects = 88\n",
    "params = macro_model.get_params()\n",
    "p_strat0 = sample_strat0(params.p_strat_trial0, num_samples, include_hs=True)\n",
    "p_transitions = tu.prepend_shape(params.p_transitions, num_samples)\n",
    "p_strat_responses = tu.prepend_shape(params.p_strat_responses, num_samples)\n",
    "p_disc_strategies = sample_p_strategies(p_strat0, p_transitions, True, num_trials)\n",
    "p_grad_strategies = sample_p_strategies(p_strat0, p_transitions, False, num_trials)\n",
    "\n",
    "# 100000 doesn't fit on GPU\n",
    "p_disc_strategies = p_disc_strategies.to('cpu')\n",
    "p_grad_strategies = p_grad_strategies.to('cpu')\n",
    "p_strat_responses = p_strat_responses.to('cpu')\n",
    "s_responses = subject_responses.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_p_response_seq = get_p_response_sequence(p_disc_strategies, p_strat_responses, s_responses)\n",
    "grad_p_response_seq = get_p_response_sequence(p_grad_strategies, p_strat_responses, s_responses)\n",
    "bayes_factor = get_bayes_factor(disc_p_response_seq, grad_p_response_seq)\n",
    "utils.kv_print(Bayes_factor=bayes_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_strategies = TensorDict(p_discrete=p_disc_strategies\n",
    "td_strategies = TensorDict(p=torch.stack([p_disc_strategies, p_grad_strategies], 0))\n",
    "df_strategies = td_strategies.to_dataframe({0: 'xtype', 1: 'sim_id', 2: 'trial', 3: 'strategy'})\n",
    "df_strategies.xtype = ['discrete' if t == 0 else 'gradual' for t in df_strategies.xtype]\n",
    "df_strategies.to_csv(dirpath + \"xtype_sim_strategies.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate responses\n",
    "num_samples = 1000\n",
    "num_trials = 25\n",
    "num_subjects = 88\n",
    "\n",
    "params = macro_model.get_params()\n",
    "p_strat0 = sample_strat0(params.p_strat_trial0, num_samples, include_hs=True)\n",
    "p_transitions = sample_p_transitions(mean_p_strat_trial0=params.p_strat_trial0,\n",
    "                                     mean_p_transitions=params.p_transitions,\n",
    "                                     num_subjects=num_subjects,\n",
    "                                     num_trials=num_trials,\n",
    "                                     num_samples=num_samples)\n",
    "p_strat_responses = sample_p_strat_responses(mean_p_strat_trial0=params.p_strat_trial0,\n",
    "                                             mean_p_transitions=params.p_transitions,\n",
    "                                             mean_p_strat_responses=params.p_strat_responses,\n",
    "                                             num_subjects=num_subjects,\n",
    "                                             num_trials=num_trials,\n",
    "                                             num_samples=num_samples)\n",
    "p_disc_strategies = sample_p_strategies(p_strat0, p_transitions, True, num_trials)\n",
    "disc_responses = sample_responses(p_disc_strategies, p_strat_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_micro_model = fit_micro_models(disc_responses,\n",
    "                                    params.p_strat_trial0,\n",
    "                                    params.p_strat_responses,\n",
    "                                    params.p_transitions,\n",
    "                                    show_pbar=True)\n",
    "disc_micro_model.responses = disc_responses.cpu()\n",
    "disc_micro_model.strategies_oh = p_disc_strategies.cpu()\n",
    "disc_micro_model.strategies = disc_micro_model.strategies_oh.argmax(-1)\n",
    "disc_micro_model.save(pickle_path + 'disc_micro_model.td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save strategy inferences\n",
    "td = TensorDict(p_actual=disc_micro_model.strategies_oh,\n",
    "                p_predicted=disc_micro_model.p_strategies)\n",
    "df = td.to_dataframe({0: 'sim', 1: 'trial', 2: 'strategy'})\n",
    "df.to_csv(dirpath + \"sim_strategy_accuracy.tsv\".format(group), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = macro_model.get_params()\n",
    "params.print(round_digits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = get_p_transitions_dirichlet_params(params.p_strat_trial0,\n",
    "                                                 params.p_transitions,\n",
    "                                                 num_subjects=88,\n",
    "                                                 num_trials=25)\n",
    "tu.round(transitions, 3, keep_device=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions = get_p_strat_responses_dirichlet_params(params.p_strat_trial0,\n",
    "                                                   params.p_transitions,\n",
    "                                                   params.p_strat_responses,\n",
    "                                                   num_subjects=88,\n",
    "                                                   num_trials=25)\n",
    "tu.round(emissions, 3, keep_device=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
